from google.cloud import bigquery, storage, pubsub_v1
import os

def bigquery_to_storage(event, context):
    client = bigquery.Client()
    storage_client = storage.Client()
    publisher = pubsub_v1.PublisherClient()
    
    project_id = os.getenv('PROJECT_ID')
    dataset_id = os.getenv('DATASET_ID')
    table_id = os.getenv('TABLE_ID')
    bucket_name = os.getenv('BUCKET_NAME')
    topic_name = os.getenv('PUBSUB_TOPIC')

    # BigQuery SQL 쿼리 실행
    query = f"SELECT * FROM `{project_id}.{dataset_id}.{table_id}`"
    results = client.query(query).result()

    # Cloud Storage에 저장할 URI 정의
    destination_uri = f"gs://{bucket_name}/Big_Query_Exam/{table_id}.csv"
    extract_job = client.extract_table(f"{project_id}.{dataset_id}.{table_id}", destination_uri)
    extract_job.result()  # 작업 완료 대기

    # 다음 작업을 트리거하기 위해 Pub/Sub에 메시지 게시
    message = f"Data exported to {destination_uri}"
    publisher.publish(topic_name, message.encode('utf-8'))

    return "BigQuery data exported to Cloud Storage and message published.", 200

###############################
TXT 파일 
google-cloud-bigquery
google-cloud-storage
google-cloud-pubsub
